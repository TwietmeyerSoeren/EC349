library(glmnet)
library(fastDummies)
library(rpart)
library(tidymodels)
library(ggpubr)
library(xgboost)
getwd()
conflicts_prefer(dplyr::summarise(), dplyr::filter, dplyr::mutate())
# Load Different Data
business_data <- stream_in(file("../data/yelp_academic_dataset_business.json"))
business_data_unnested <- unnest(business_data, attributes)
checkin_data  <- stream_in(file("../data/yelp_academic_dataset_checkin.json"))
tip_data  <- stream_in(file("../data/yelp_academic_dataset_tip.json"))
# Load smaller data sets for comparative purposes and easier testing
load("../data/yelp_review_small.Rda")
load("../data/yelp_user_small.Rda")
# source functions
source("../code/assignment_functions.R")
# business data
#str(business_data_unnested)
empty_rows_business_data <- count_empty_rows(business_data_unnested)
length(unique(business_data_unnested$business_id))
cols_keep_business_data <- empty_rows_business_data %>% filter(`EmptyRows` < 35000 & !Column %in% c('name', 'address', 'latitude', 'longitude'))
# review data
#str(review_data_small)
length(unique(review_data_small$review_id))
# check in data
#str(checkin_data)
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
# user data
#str(user_data_small)
length(unique(user_data_small$user_id))
# tip data
#str(tip_data)
# investigate relationships between different columns and stars_review
## tip data:
num_comments_by_business <- tip_data %>% group_by(business_id) %>% summarise(total_comments_business = n())
# user data:
user_data_selected <- user_data_small  %>% mutate(yelping_since_weeks = round(as.numeric(difftime("2023-12-31 00:00:00", yelping_since, units = "weeks")), digits = 0), num_friends = ifelse(friends != "None", sapply(strsplit(friends, ","), function(x) length(x)), 0), total_compliments = select(., starts_with("compliment_")) %>% rowSums(na.rm = TRUE)) %>% mutate(was_elite = ifelse(nchar(elite) > 1, 1, 0))%>%  select(-c(name, yelping_since, friends))
# check in data
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
# merge other data sets onto review data which is the main one:
review_data_combined <- review_data_small %>% left_join(business_data_unnested[, cols_keep_business_data$Column], by = 'business_id', suffix = c('_review', '_business')) %>% left_join(user_data_selected, by = 'user_id', suffix = c('_review', '_user')) %>% left_join(num_comments_by_business, by = 'business_id') %>% left_join(check_ins_by_business, by = "business_id") %>% mutate(BusinessAcceptsCreditCards = ifelse(BusinessAcceptsCreditCards == "True", 1, 0))
# see how columns are populated
# view(count_empty_rows(review_data_combined))
# business info:
business_review_comp <- ggplot(review_data_combined, mapping = aes(x = stars_business, y = stars_review)) + geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Mean rating of a business", y = "User Rating", title = str_wrap("Relationship between user ratings and average business ratings", 50)) + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1.5, 'cm'),text = element_text(colour = 'black', size = 16))
num_coms_business <- trend_plot("total_comments_business", 1)
city_plot <- ggplot(review_data_combined %>% group_by(city) %>% dplyr::summarise(mean_by_city = mean(stars_review)), mapping = aes(x = city, y= mean_by_city)) + geom_col() # clear differences in average ratings by city
state_plot <- ggplot(review_data_combined %>% group_by(state) %>% dplyr::summarise(mean_by_state = mean(stars_review)), mapping = aes(x = state, y= mean_by_state)) + geom_col() + labs(x = "State", y = "Mean Rating", title = "Average rating in each state") + theme_pubr()+ theme(text = element_text(colour = 'black', size = 12)) # clear differences in average ratings by state
credit_card_plot <- trend_plot("BusinessAcceptsCreditCards", 0) # slight downward trend
mean(review_data_combined$BusinessAcceptsCreditCards, na.rm = TRUE)
is_open_plot <- trend_plot("is_open", 0) # slight upwards trend
mean(review_data_combined$is_open)
# review info:
usefulness_info_plot <- trend_plot("useful_review", 1)
funny_info_plot <- trend_plot("funny_review", 1)
cool_info_plot <- trend_plot("cool_review", 1)
review_count_plot <- trend_plot("review_count_review", 0) ## slight positive correlation, slightly non-linear
# user info:
friends_count_plot <- trend_plot("num_friends", 1) ## slight positive correlation
fans_count_plot <- trend_plot("fans", 1) ## slight positive correlation
compliments_count_plot <- trend_plot("total_compliments", 1) ## slight positive correlation
yelp_since_plot <- trend_plot("yelping_since_weeks", 0) ## slight positive relationship
yelping_since_fancy_plot <- ggplot(review_data_combined, mapping = aes(x = yelping_since_weeks, y = stars_review)) +
geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Number of weeks since a user joined Yelp", y = "User Rating", title = "Relationship length of Yelp usership and ratings") + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1, 'cm'),text = element_text(colour = 'black', size = 12))
# check-in data
num_checkins_plot <- ggplot(review_data_combined, mapping = aes(x = num_checkins_by_business, y = stars_review)) +
geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Number of check-ins made on a business", y = "User Rating", title = str_wrap("Relationship between the number of business check-ins and user ratings", 50)) + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1, 'cm'),text = element_text(colour = 'black', size = 12))
# create one data frame that contains all the useful information
## business data
cols_keep_business_data <- count_empty_rows(business_data_unnested) %>% filter(`EmptyRows` < 0.25*nrow(business_data_unnested) & !Column %in% c('name', 'address', 'latitude', 'longitude'))
business_data_selected <- dummy_cols(business_data_unnested[, cols_keep_business_data$Column], select_columns = c('state'), remove_selected_columns = FALSE, remove_first_dummy  = TRUE) %>% mutate(BusinessAcceptsCreditCards = ifelse(BusinessAcceptsCreditCards == "True", 1, 0))
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
num_comments_by_business <- tip_data %>% group_by(business_id) %>% summarise(total_comments_business = n())
# merge business_data, check_in_data, and tip_data onto review data which is the main one:
combined_df <- review_data_small %>% left_join(business_data_selected, by = 'business_id', suffix = c('_review', '_business')) %>% left_join(num_comments_by_business, by = 'business_id') %>% left_join(check_ins_by_business, by = "business_id")
# find all columns that have enough populated cells, drop the rest
combined_df_empty_rows <- count_empty_rows(combined_df) %>% filter(`EmptyRows` < 0.2*nrow(combined_df))
# drop all rows that have any remaining missing values after the columns have been selected since the models can't handle missing values
combined_df_filtered <- combined_df[, combined_df_empty_rows$Column] %>% na.omit()
# reduce the file size to be able to deal with a lack of computing power
set.seed(1)
file_reduction_indeces <- sample(1:nrow(combined_df_filtered), nrow(combined_df_filtered) - 400000)
combined_df_sliced <-combined_df_filtered[file_reduction_indeces,]
## add the text from the comments in a cleaned way such that it can be included in our models
df_part_one <- generate_final_df(1, 40000, combined_df_sliced)
df_part_two <- generate_final_df(40001, 80000, combined_df_sliced)
df_part_three <- generate_final_df(80001, 120000, combined_df_sliced)
# save the data frame so that we don't have to generate it over and over again
df_combined <- bind_rows(df_part_one, df_part_two, df_part_three)
# manipulate data so that columns get filled with 0s
cols_to_change <- colnames(df_combined)[46:length(colnames(df_combined))]
df_combined_updated <- df_combined %>% mutate_at(vars(cols_to_change), ~replace_na(., 0))
final_dataset <- df_combined_updated %>%  select(-c("date", "text", starts_with("compliment_"), "review_id", "business_id", "user_id", "city", "postal_code", "categories")) %>% mutate(useful_sq = I(useful^2), useful_cube = I(useful^3), funny_sq = I(funny^2), funny_cube = I(funny^3), cool_review_sq = I(cool_review^2), cool_review_cube = I(cool_review^3), num_checkins_by_business_sq = I(num_checkins_by_business^2), num_checkins_by_business_cube = I(num_checkins_by_business^3))
#Split data into test and training
set.seed(1)
train <- sample(1:nrow(final_dataset), nrow(final_dataset) - 10000) #keep 10,000 for the test data
data_train <-final_dataset[train,]
#Test data
data_test <- final_dataset[-train,]
# for shrinkage estimators we need to transform data into matrices, therefore we need the following transformation:
data_train_x <-data_train[,!colnames(data_train) %in% c("stars_review", "state")]
data_train_y <-data_train[,c("stars_review")]
data_test_x <-data_test[, !colnames(data_test) %in% c("stars_review", "state")]
data_test_y <-data_test[,c("stars_review")]
ridge_results <- shrinkage_estimator_computation(0, data_train_x, data_train_y, data_test_x, data_test_y)
cv_out_ridge <- ridge_results$cv_out
plot_cv_out_ridge <- ridge_results$cv_out_plot
lambda_ridge_cv<- ridge_results$lambda_cv
ridge_model<- ridge_results$model
ridge_mse <- ridge_results$mse
ridge_mse_training <- ridge_results$mse_training
ridge_rsq <- ridge_results$rsq
ridge_rsq_training <- ridge_results$rsq_training
coef(ridge_model)
lasso_results <- shrinkage_estimator_computation(1, data_train_x, data_train_y, data_test_x, data_test_y)
cv_out_lasso <- lasso_results$cv_out
plot_cv_out_lasso <- lasso_results$cv_out_plot
lambda_lasso_cv <- lasso_results$lambda_cv
lasso_model<- lasso_results$model
lasso_mse <- lasso_results$mse
lasso_mse_training <- lasso_results$mse_training
lasso_rsq <- lasso_results$rsq
lasso_rsq_training <- lasso_results$rsq_training
coefficients_lasso <- coef(lasso_model)
as.data.frame(coefficients_lasso)
as.data.frame(coefficients_lasso[,])
colnames(as.data.frame(coefficients_lasso[,]))
library(tibble)
as.data.frame(coefficients_lasso[,]) %>% rownames_to_column(var = "term")
coefficients_ridge <- coef(ridge_model) %>% as.data.frame() %>% rownames_to_column(var = "term")
coefficients_ridge <- coef(ridge_model)[,] %>% as.data.frame() %>% rownames_to_column(var = "term")
View(coefficients_ridge)
View(coefficients_ridge)
coefficients_ridge <- coef(ridge_model)[,] %>% as.data.frame() %>% rownames_to_column(var = "term") %>% setNames(c("term", "coefficient"))
View(coefficients_ridge)
coefficients_ridge <- coef(ridge_model)[,] %>% as.data.frame() %>% rownames_to_column(var = "term") %>% setNames(c("term", "coefficient")) %>% mutate(coefficient_abs_value = abs(coefficient))
highest_lowest_coefficients_ridge <- rbind( coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(desc(coefficient)) %>% slice(1:7), coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(coefficient) %>% slice(1:7))
highest_lowest_coefficients_ridge <- rbind( coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(desc(coefficient)) %>% dplyr::slice(1:7), coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(coefficient) %>% dplyr::slice(1:7))
View(highest_lowest_coefficients_ridge)
highest_lowest_coefficients_ridge <- rbind( coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(desc(coefficient)) %>% dplyr::slice(1:7), coefficients_ridge[37:nrow(coefficients_ridge), ] %>% arrange(coefficient) %>% dplyr::slice(1:7)) %>% arrange(desc(coefficient))
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_lasso, aes(x = "term", y = "coefficient")) %>% geom_bar()
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, aes(x = "term", y = "coefficient")) %>% geom_bar()
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, aes(x = "term", y = "coefficient")) + geom_bar()
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, aes(x = "term", y = "coefficient")) + geom_histogram()
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, aes(x = term, y = coefficient)) + geom_bar()
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, mapping = aes(x = term, y = coefficient)) + geom_col()
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, mapping = aes(reorder(term, coefficient, sum), coefficient)) + geom_col()
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, mapping = aes(reorder(term, coefficient, sum), coefficient)) + geom_col() + labs(x = "Word used", y = "Coefficient", title = "Coefficient of words used in review") + theme_pubr()+ theme(text = element_text(colour = 'black', size = 12))
coef_plot_lasso
coef_plot_lasso <- ggplot(data = highest_lowest_coefficients_ridge, mapping = aes(reorder(term, coefficient, sum), coefficient)) + geom_col() + labs(x = "Word used", y = "Coefficient", title = "Coefficient of words used in review")
coef_plot_lasso
?reorder
?xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 1)
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.2)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.15)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 75,
verbose = 1,
objective = "reg:squarederror",
eta = 0.15)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.175)
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.175)
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
hi
nrounds = 100,
verbose = 1,
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.2,
max_depth = 5)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 50,
verbose = 1,
objective = "reg:squarederror",
eta = 0.2,
max_depth = 5)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.2,
max_depth = 7)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.2,
max_depth = 8)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.25,
max_depth = 8)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.25,
max_depth = 6)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
model_performance_xgboost
xgb_model <- xgboost(data = as.matrix(data_train[, !colnames(data_train) %in% c("stars_review", "state")]),
label = data_train$stars_review,
nrounds = 100,
verbose = 1,
objective = "reg:squarederror",
eta = 0.25,
max_depth = 8)
# Predictions on the test data
predictions_xgboost <- predict(xgb_model, as.matrix(data_test[, !colnames(data_train) %in% c("stars_review", "state")]))
model_performance_xgboost <- data_test %>%
mutate(predictions = predictions_xgboost) %>%
metrics(truth = stars_review, estimate = predictions)
coef_plot_lasso
view(count_empty_rows(review_data_combined))
standard_tree_spec <- rpart(stars_review ~ ., data = data_train, max_depth = 8)
coef_plot_lasso
lm_stars<- lm(stars_review ~ cool_review + I(cool_review^2) + I(cool_review^3) + review_count + useful + I(useful^2)+ I(useful^3) + funny + I(funny^2) + I(funny^3)+ stars_business + total_comments_business + state + is_open + num_checkins_by_business + I(num_checkins_by_business^2) + I(num_checkins_by_business^3) + worst + terribl + rude + money + lack + dri + wont + thank + best + profession + fantast + excel + awesom + amaz, data = data_train)
#Review the results
coefs_lrm <- coeftest(lm_stars, vcov = vcovHC(lm_stars, type="HC3"))
lm_stars<- lm(stars_review ~ cool_review + I(cool_review^2) + I(cool_review^3) + review_count + useful + I(useful^2)+ I(useful^3) + funny + I(funny^2) + I(funny^3)+ stars_business + total_comments_business + state + is_open + num_checkins_by_business + I(num_checkins_by_business^2) + I(num_checkins_by_business^3) + worst + terribl + rude + money + lack + dri + wont + thank + best + profession + fantast + excel + awesom + amaz, data = data_train)
#Review the results
#coefs_lrm <- coeftest(lm_stars, vcov = vcovHC(lm_stars, type="HC3"))
#Prediction to test data
lm_stars_predict<-predict(lm_stars, newdata = data_test[, !colnames(data_test) %in% c("stars_review")])
#Empirical MSE in TEST data
lm_stars_test_mse<-mean((lm_stars_predict-data_test$stars_review)^2)
lm_stars<- lm(stars_review ~ cool_review + I(cool_review^2) + I(cool_review^3) + review_count + useful + I(useful^2)+ I(useful^3) + funny + I(funny^2) + I(funny^3)+ stars_business + total_comments_business + state + is_open + num_checkins_by_business + I(num_checkins_by_business^2) + I(num_checkins_by_business^3) , data = data_train)
#Review the results
#coefs_lrm <- coeftest(lm_stars, vcov = vcovHC(lm_stars, type="HC3"))
#Prediction to test data
lm_stars_predict<-predict(lm_stars, newdata = data_test[, !colnames(data_test) %in% c("stars_review")])
#Empirical MSE in TEST data
lm_stars_test_mse<-mean((lm_stars_predict-data_test$stars_review)^2)
lm_stars <- lm(stars_review ~., data = data_train)
#Review the results
#coefs_lrm <- coeftest(lm_stars, vcov = vcovHC(lm_stars, type="HC3"))
#Prediction to test data
lm_stars_predict<-predict(lm_stars, newdata = data_test[, !colnames(data_test) %in% c("stars_review")])
#Empirical MSE in TEST data
lm_stars_test_mse<-mean((lm_stars_predict-data_test$stars_review)^2)
view(coefficients_lasso %>% filter(coefficient_abs_value > 0.1))
view(coefficients_ridge %>% filter(coefficient_abs_value > 0.1))
rm(list = ls())
library(conflicted)
library(jsonlite)
library(tidyverse)
library(dplyr)
library(tidyr)
library(tm)
library(hexbin)
library(doParallel)
library(glmnet)
library(fastDummies)
library(rpart)
library(tidymodels)
library(ggpubr)
library(xgboost)
getwd()
conflicts_prefer(dplyr::summarise(), dplyr::filter, dplyr::mutate())
# Load Different Data
business_data <- stream_in(file("../data/yelp_academic_dataset_business.json"))
business_data_unnested <- unnest(business_data, attributes)
checkin_data  <- stream_in(file("../data/yelp_academic_dataset_checkin.json"))
tip_data  <- stream_in(file("../data/yelp_academic_dataset_tip.json"))
# Load smaller data sets for comparative purposes and easier testing
load("../data/yelp_review_small.Rda")
load("../data/yelp_user_small.Rda")
# source functions
source("../code/assignment_functions.R")
# business data
#str(business_data_unnested)
empty_rows_business_data <- count_empty_rows(business_data_unnested)
length(unique(business_data_unnested$business_id))
cols_keep_business_data <- empty_rows_business_data %>% filter(`EmptyRows` < 35000 & !Column %in% c('name', 'address', 'latitude', 'longitude'))
# review data
#str(review_data_small)
length(unique(review_data_small$review_id))
# check in data
#str(checkin_data)
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
# user data
#str(user_data_small)
length(unique(user_data_small$user_id))
# tip data
#str(tip_data)
# investigate relationships between different columns and stars_review
## tip data:
num_comments_by_business <- tip_data %>% group_by(business_id) %>% summarise(total_comments_business = n())
# user data:
user_data_selected <- user_data_small  %>% mutate(yelping_since_weeks = round(as.numeric(difftime("2023-12-31 00:00:00", yelping_since, units = "weeks")), digits = 0), num_friends = ifelse(friends != "None", sapply(strsplit(friends, ","), function(x) length(x)), 0), total_compliments = select(., starts_with("compliment_")) %>% rowSums(na.rm = TRUE)) %>% mutate(was_elite = ifelse(nchar(elite) > 1, 1, 0))%>%  select(-c(name, yelping_since, friends))
# check in data
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
# merge other data sets onto review data which is the main one:
review_data_combined <- review_data_small %>% left_join(business_data_unnested[, cols_keep_business_data$Column], by = 'business_id', suffix = c('_review', '_business')) %>% left_join(user_data_selected, by = 'user_id', suffix = c('_review', '_user')) %>% left_join(num_comments_by_business, by = 'business_id') %>% left_join(check_ins_by_business, by = "business_id") %>% mutate(BusinessAcceptsCreditCards = ifelse(BusinessAcceptsCreditCards == "True", 1, 0))
# see how columns are populated
#view(count_empty_rows(review_data_combined))
# business info:
business_review_comp <- ggplot(review_data_combined, mapping = aes(x = stars_business, y = stars_review)) + geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Mean rating of a business", y = "User Rating", title = str_wrap("Relationship between user ratings and average business ratings", 50)) + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1.5, 'cm'),text = element_text(colour = 'black', size = 16))
num_coms_business <- trend_plot("total_comments_business", 1)
city_plot <- ggplot(review_data_combined %>% group_by(city) %>% dplyr::summarise(mean_by_city = mean(stars_review)), mapping = aes(x = city, y= mean_by_city)) + geom_col() # clear differences in average ratings by city
state_plot <- ggplot(review_data_combined %>% group_by(state) %>% dplyr::summarise(mean_by_state = mean(stars_review)), mapping = aes(x = state, y= mean_by_state)) + geom_col() + labs(x = "State", y = "Mean Rating", title = "Average rating in each state") + theme_pubr()+ theme(text = element_text(colour = 'black', size = 12)) # clear differences in average ratings by state
credit_card_plot <- trend_plot("BusinessAcceptsCreditCards", 0) # slight downward trend
mean(review_data_combined$BusinessAcceptsCreditCards, na.rm = TRUE)
is_open_plot <- trend_plot("is_open", 0) # slight upwards trend
mean(review_data_combined$is_open)
# review info:
usefulness_info_plot <- trend_plot("useful_review", 1)
funny_info_plot <- trend_plot("funny_review", 1)
cool_info_plot <- trend_plot("cool_review", 1)
review_count_plot <- trend_plot("review_count_review", 0) ## slight positive correlation, slightly non-linear
# user info:
friends_count_plot <- trend_plot("num_friends", 1) ## slight positive correlation
fans_count_plot <- trend_plot("fans", 1) ## slight positive correlation
compliments_count_plot <- trend_plot("total_compliments", 1) ## slight positive correlation
yelp_since_plot <- trend_plot("yelping_since_weeks", 0) ## slight positive relationship
yelping_since_fancy_plot <- ggplot(review_data_combined, mapping = aes(x = yelping_since_weeks, y = stars_review)) +
geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Number of weeks since a user joined Yelp", y = "User Rating", title = "Relationship length of Yelp usership and ratings") + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1, 'cm'),text = element_text(colour = 'black', size = 12))
# check-in data
num_checkins_plot <- ggplot(review_data_combined, mapping = aes(x = num_checkins_by_business, y = stars_review)) +
geom_hex() + geom_smooth(method = "glm", formula = y ~ x + I(x^2) + I(x^3)) + ylim(1,5) + labs(x = "Number of check-ins made on a business", y = "User Rating", title = str_wrap("Relationship between the number of business check-ins and user ratings", 50)) + theme_pubr()+ theme(legend.title = element_blank(), legend.position = 'right', legend.key.height = unit(1, 'cm'),text = element_text(colour = 'black', size = 12))
# create one data frame that contains all the useful information
## business data
cols_keep_business_data <- count_empty_rows(business_data_unnested) %>% filter(`EmptyRows` < 0.25*nrow(business_data_unnested) & !Column %in% c('name', 'address', 'latitude', 'longitude'))
business_data_selected <- dummy_cols(business_data_unnested[, cols_keep_business_data$Column], select_columns = c('state'), remove_selected_columns = FALSE, remove_first_dummy  = TRUE) %>% mutate(BusinessAcceptsCreditCards = ifelse(BusinessAcceptsCreditCards == "True", 1, 0))
check_ins_by_business <- checkin_data  %>% mutate(num_checkins_by_business = ifelse(date != "None", sapply(strsplit(date, ","), function(x) length(x)), 0)) %>% select(-"date")
num_comments_by_business <- tip_data %>% group_by(business_id) %>% summarise(total_comments_business = n())
# merge business_data, check_in_data, and tip_data onto review data which is the main one:
combined_df <- review_data_small %>% left_join(business_data_selected, by = 'business_id', suffix = c('_review', '_business')) %>% left_join(num_comments_by_business, by = 'business_id') %>% left_join(check_ins_by_business, by = "business_id")
# find all columns that have enough populated cells, drop the rest
combined_df_empty_rows <- count_empty_rows(combined_df) %>% filter(`EmptyRows` < 0.2*nrow(combined_df))
# drop all rows that have any remaining missing values after the columns have been selected since the models can't handle missing values
combined_df_filtered <- combined_df[, combined_df_empty_rows$Column] %>% na.omit()
# reduce the file size to be able to deal with a lack of computing power
set.seed(1)
file_reduction_indeces <- sample(1:nrow(combined_df_filtered), nrow(combined_df_filtered) - 400000)
combined_df_sliced <-combined_df_filtered[file_reduction_indeces,]
## add the text from the comments in a cleaned way such that it can be included in our models
df_part_one <- generate_final_df(1, 270000, combined_df_sliced)
df_part_two <- generate_final_df(270001, 540000, combined_df_sliced)
df_part_three <- generate_final_df(540001, nrow(combined_df_sliced), combined_df_sliced)
# save the data frame so that we don't have to generate it over and over again
df_combined <- bind_rows(df_part_one, df_part_two, df_part_three)
# manipulate data so that columns get filled with 0s
cols_to_change <- colnames(df_combined)[46:length(colnames(df_combined))]
df_combined_updated <- df_combined %>% mutate_at(vars(cols_to_change), ~replace_na(., 0))
final_dataset <- df_combined_updated %>%  select(-c("date", "text", starts_with("compliment_"), "review_id", "business_id", "user_id", "city", "postal_code", "categories")) %>% mutate(useful_sq = I(useful^2), useful_cube = I(useful^3), funny_sq = I(funny^2), funny_cube = I(funny^3), cool_review_sq = I(cool_review^2), cool_review_cube = I(cool_review^3), num_checkins_by_business_sq = I(num_checkins_by_business^2), num_checkins_by_business_cube = I(num_checkins_by_business^3))
#Split data into test and training
set.seed(1)
train <- sample(1:nrow(final_dataset), nrow(final_dataset) - 10000) #keep 10,000 for the test data
data_train <-final_dataset[train,]
#Test data
data_test <- final_dataset[-train,]
# for shrinkage estimators we need to transform data into matrices, therefore we need the following transformation:
data_train_x <-data_train[,!colnames(data_train) %in% c("stars_review", "state")]
data_train_y <-data_train[,c("stars_review")]
data_test_x <-data_test[, !colnames(data_test) %in% c("stars_review", "state")]
data_test_y <-data_test[,c("stars_review")]
### Linear Models
##Linear Regression Model of stars given for a review as a function of user, business, and review characteristics
#lm_stars<- lm(stars_review ~ cool_review + I(cool_review^2) + I(cool_review^3) + review_count + useful + I(useful^2)+ I(useful^3) + funny + I(funny^2) + I(funny^3)+ stars_business + total_comments_business + state + is_open + num_checkins_by_business + I(num_checkins_by_business^2) + I(num_checkins_by_business^3) + worst + terribl + rude + money + lack + dri + wont + thank + best + profession + fantast + excel + awesom + amaz, data = data_train)
lm_stars <- lm(stars_review ~., data = data_train)
#Prediction to test data
lm_stars_predict<-predict(lm_stars, newdata = data_test[, !colnames(data_test) %in% c("stars_review")])
#Empirical MSE in TEST data
lm_stars_test_mse<-mean((lm_stars_predict-data_test$stars_review)^2)
## LASSO and Ridge
ridge_results <- shrinkage_estimator_computation(0, data_train_x, data_train_y, data_test_x, data_test_y)
set.seed(1)
file_reduction_indeces <- sample(1:nrow(combined_df_filtered), nrow(combined_df_filtered) - 600000)
combined_df_sliced <-combined_df_filtered[file_reduction_indeces,]
## add the text from the comments in a cleaned way such that it can be included in our models
df_part_one <- generate_final_df(1, 270000, combined_df_sliced)
df_part_two <- generate_final_df(270001, 540000, combined_df_sliced)
df_part_three <- generate_final_df(540001, nrow(combined_df_sliced), combined_df_sliced)
# save the data frame so that we don't have to generate it over and over again
df_combined <- bind_rows(df_part_one, df_part_two, df_part_three)
# manipulate data so that columns get filled with 0s
cols_to_change <- colnames(df_combined)[46:length(colnames(df_combined))]
df_combined_updated <- df_combined %>% mutate_at(vars(cols_to_change), ~replace_na(., 0))
final_dataset <- df_combined_updated %>%  select(-c("date", "text", starts_with("compliment_"), "review_id", "business_id", "user_id", "city", "postal_code", "categories")) %>% mutate(useful_sq = I(useful^2), useful_cube = I(useful^3), funny_sq = I(funny^2), funny_cube = I(funny^3), cool_review_sq = I(cool_review^2), cool_review_cube = I(cool_review^3), num_checkins_by_business_sq = I(num_checkins_by_business^2), num_checkins_by_business_cube = I(num_checkins_by_business^3))
#Split data into test and training
set.seed(1)
train <- sample(1:nrow(final_dataset), nrow(final_dataset) - 10000) #keep 10,000 for the test data
data_train <-final_dataset[train,]
#Test data
data_test <- final_dataset[-train,]
# for shrinkage estimators we need to transform data into matrices, therefore we need the following transformation:
data_train_x <-data_train[,!colnames(data_train) %in% c("stars_review", "state")]
data_train_y <-data_train[,c("stars_review")]
data_test_x <-data_test[, !colnames(data_test) %in% c("stars_review", "state")]
data_test_y <-data_test[,c("stars_review")]
### Linear Models
##Linear Regression Model of stars given for a review as a function of user, business, and review characteristics
#lm_stars<- lm(stars_review ~ cool_review + I(cool_review^2) + I(cool_review^3) + review_count + useful + I(useful^2)+ I(useful^3) + funny + I(funny^2) + I(funny^3)+ stars_business + total_comments_business + state + is_open + num_checkins_by_business + I(num_checkins_by_business^2) + I(num_checkins_by_business^3) + worst + terribl + rude + money + lack + dri + wont + thank + best + profession + fantast + excel + awesom + amaz, data = data_train)
lm_stars <- lm(stars_review ~., data = data_train)
#Prediction to test data
lm_stars_predict<-predict(lm_stars, newdata = data_test[, !colnames(data_test) %in% c("stars_review")])
#Empirical MSE in TEST data
lm_stars_test_mse<-mean((lm_stars_predict-data_test$stars_review)^2)
## LASSO and Ridge
ridge_results <- shrinkage_estimator_computation(0, data_train_x, data_train_y, data_test_x, data_test_y)
install.packages("computers")
library(computers)
version
version
